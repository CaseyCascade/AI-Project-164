{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d35f38f",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38dcbaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset basis\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Tools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Tokenizes sentences\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "# Models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c13dbd",
   "metadata": {},
   "source": [
    "We must first fetch the datasets that will be used in the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccc7ed50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST...\n",
      "Loading EMNIST...\n",
      "Loading IMDB_Sentiment...\n"
     ]
    }
   ],
   "source": [
    "# 1) Load MNIST\n",
    "print(\"Loading MNIST...\")\n",
    "mnist = fetch_openml(\"mnist_784\", version=1, as_frame=False)\n",
    "\n",
    "# 2) Load EMNIST\n",
    "print(\"Loading EMNIST...\")\n",
    "emnist = fetch_openml(\"EMNIST_Balanced\", version=1, as_frame=False)\n",
    "\n",
    "# 3) Load IMDB_Sentiment\n",
    "print(\"Loading IMDB_Sentiment...\")\n",
    "dataset = load_dataset(\"Kwaai/IMDB_Sentiment\", split=\"train\").shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bf9faa",
   "metadata": {},
   "source": [
    "There will be 3 main models we will be using between these 3 differing datasets, those include K Nearest Neighbors, Naive Bayes, and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a518f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train, X_test, y_train, y_test):\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_knn = knn.predict(X_test)\n",
    "    accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    print(f\"K Nearest Neighbors' Accuracy: {accuracy_knn:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d53b62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB(X_train, X_test, y_train, y_test):\n",
    "    nb_classifier = MultinomialNB()\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    y_pred_nb = nb_classifier.predict(X_test)\n",
    "    accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "    print(f\"Naive Bayes' Accuracy: {accuracy_nb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f116babc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(X_train, X_test, y_train, y_test):\n",
    "    logreg_classifier = LogisticRegression(max_iter=1000)\n",
    "    logreg_classifier.fit(X_train, y_train)\n",
    "    y_pred_logreg = logreg_classifier.predict(X_test)\n",
    "    accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "    print(f\"Logistic Regression's Accuracy: {accuracy_logreg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa19682",
   "metadata": {},
   "source": [
    "Prepare The MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbea36eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Normalize MNIST Balanced\n",
    "X, y = mnist.data, mnist.target.astype(int)\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "X = X / 255.0\n",
    "\n",
    "# Optional: Apply PCA to reduce dimensionality\n",
    "USE_PCA = False\n",
    "if USE_PCA:\n",
    "    pca = PCA(n_components=100)  # Try 50–150\n",
    "    X = pca.fit_transform(X)\n",
    "\n",
    "# 2) Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f383a9",
   "metadata": {},
   "source": [
    "Plug It Into Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "142dcc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputting MNIST...\n",
      "K Nearest Neighbors' Accuracy: 0.97\n",
      "Naive Bayes' Accuracy: 0.8184\n",
      "Logistic Regression's Accuracy: 0.9224\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputting MNIST...\")\n",
    "KNN(X_train, X_test, y_train, y_test)\n",
    "NB(X_train, X_test, y_train, y_test)\n",
    "LR(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d80c44",
   "metadata": {},
   "source": [
    "Prepare The EMNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06200218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Normalize EMNIST Balanced\n",
    "X, y = emnist.data, emnist.target.astype(int)\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "X = X / 255.0\n",
    "\n",
    "# Optional: Apply PCA to reduce dimensionality\n",
    "USE_PCA = False\n",
    "if USE_PCA:\n",
    "    pca = PCA(n_components=100)  # Try 50–150\n",
    "    X = pca.fit_transform(X)\n",
    "\n",
    "# 2) Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e700fd3",
   "metadata": {},
   "source": [
    "Plug It Into Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbc95d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputting EMNIST...\n",
      "K Nearest Neighbors' Accuracy: 0.79\n",
      "Naive Bayes' Accuracy: 0.5395\n",
      "Logistic Regression's Accuracy: 0.6920\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputting EMNIST...\")\n",
    "KNN(X_train, X_test, y_train, y_test)\n",
    "NB(X_train, X_test, y_train, y_test)\n",
    "LR(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b1802a",
   "metadata": {},
   "source": [
    "Prepare The IMDB_Sentiment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "974a688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier's plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it's the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...\n"
     ]
    }
   ],
   "source": [
    "# Show a sample text\n",
    "print(dataset[0][\"text\"])\n",
    "\n",
    "# Select a smaller subset for faster training\n",
    "dataset = dataset.select(range(1000))\n",
    "\n",
    "# Extract text and labels\n",
    "texts = dataset[\"text\"]\n",
    "labels = dataset[\"label\"]\n",
    "\n",
    "# TF-IDF Vectorization; Tokenizes\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "y = np.array(dataset[\"label\"])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d7b0e",
   "metadata": {},
   "source": [
    "Plug It Into Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2bb51b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputting IMBd_Sentiment...\n",
      "K Nearest Neighbors' Accuracy: 0.60\n",
      "Naive Bayes' Accuracy: 0.7350\n",
      "Logistic Regression's Accuracy: 0.8050\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputting IMBd_Sentiment...\")\n",
    "KNN(X_train, X_test, y_train, y_test)\n",
    "NB(X_train, X_test, y_train, y_test)\n",
    "LR(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
